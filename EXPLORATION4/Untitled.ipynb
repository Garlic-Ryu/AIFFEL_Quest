{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97458ccb",
   "metadata": {},
   "source": [
    "# Exploration4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5476aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.3\n",
      "0.5.2\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import konlpy\n",
    "import gensim\n",
    "from tensorflow import keras\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1880771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from collections import Counter\n",
    "import os\n",
    "from konlpy.tag import Mecab\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from tensorflow.keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359da64",
   "metadata": {},
   "source": [
    "# 1) 데이터 준비와 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "281f69b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbda28",
   "metadata": {},
   "source": [
    "# 2) 데이터로더 구성\n",
    "실습 때 다루었던 IMDB 데이터셋은 텍스트를 가공하여 imdb.data_loader() 메서드를 호출하면 숫자 인덱스로 변환된 텍스트와 word_to_index 딕셔너리까지 친절하게 제공합니다. 그러나 이번에 다루게 될 nsmc 데이터셋은 전혀 가공되지 않은 텍스트 파일로 이루어져 있습니다. 이것을 읽어서 imdb.data_loader()와 동일하게 동작하는 자신만의 data_loader를 만들어 보는 것으로 시작합니다. data_loader 안에서는 다음을 수행해야 합니다.\n",
    "\n",
    "데이터의 중복 제거\n",
    "NaN 결측치 제거\n",
    "한국어 토크나이저로 토큰화\n",
    "불용어(Stopwords) 제거\n",
    "사전word_to_index 구성\n",
    "텍스트 스트링을 사전 인덱스 스트링으로 변환\n",
    "X_train, y_train, X_test, y_test, word_to_index 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca739394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "\n",
    "def load_data(train_data, test_data, num_words=10000):\n",
    "    train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    train_data = train_data.dropna(how = 'any') \n",
    "    test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "    test_data = test_data.dropna(how = 'any') \n",
    "\n",
    "    X_train = []\n",
    "    for sentence in train_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(temp_X)\n",
    "\n",
    "    X_test = []\n",
    "    for sentence in test_data['document']:\n",
    "        temp_X = tokenizer.morphs(sentence) # 토큰화\n",
    "        temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(temp_X)\n",
    "\n",
    "    words = np.concatenate(X_train).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(10000-4)\n",
    "    vocab = ['<PAD>', '<BOS>', '<UNK>', '<UNUSED>'] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in wordlist]\n",
    "\n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "\n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "\n",
    "\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1dde762",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = {index:word for word, index in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7941c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86eb62b",
   "metadata": {},
   "source": [
    "# 3) 모델 구성을 위한 데이터 분석 및 가공\n",
    "데이터셋 내 문장 길이 분포\n",
    "적절한 최대 문장 길이 지정\n",
    "keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f300c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  15.96940191154864\n",
      "문장길이 최대 :  116\n",
      "문장길이 표준편차 :  12.843571191092\n",
      "pad_sequences maxlen :  41\n",
      "전체 문장의 0.9342988343341575%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(X_train) + list(X_test)\n",
    "\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens) # 최대 길이\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n",
    "\n",
    "# 패딩 추가\n",
    "# 가장 마지막 위치의 단어가 state에 가장 많은 영향을 미치므로 padding은 pre로 지정.\n",
    "X_train = keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='pre',\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "X_test = keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='pre',\n",
    "                                                       maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3182395f",
   "metadata": {},
   "source": [
    "# 4) 모델 구성 및 validation set 구성\n",
    "모델은 3가지 이상 다양하게 구성하여 실험해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56596304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126182, 41)\n",
      "(126182,)\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 중 20000개를 validation set으로 사용\n",
    "X_val = X_train[:20000]   \n",
    "y_val = y_train[:20000]\n",
    "\n",
    "partial_X_train = X_train[20000:]  \n",
    "partial_y_train = y_train[20000:]\n",
    "\n",
    "print(partial_X_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c47377d",
   "metadata": {},
   "source": [
    "## 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bffd1137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 8)                 6688      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,006,769\n",
      "Trainable params: 2,006,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 16)          22416     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 2,024,513\n",
      "Trainable params: 2,024,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 8)                 1608      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,001,617\n",
      "Trainable params: 2,001,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200\n",
    "\n",
    "# LSTM\n",
    "lstm = keras.Sequential()\n",
    "lstm.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "lstm.add(keras.layers.LSTM(8))\n",
    "lstm.add(keras.layers.Dense(8, activation='relu'))\n",
    "lstm.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm.summary()\n",
    "\n",
    "# 1-D CNN\n",
    "cnn = keras.Sequential()\n",
    "cnn.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,))) \n",
    "cnn.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn.add(keras.layers.MaxPooling1D(5))\n",
    "cnn.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "cnn.add(keras.layers.GlobalMaxPooling1D())\n",
    "cnn.add(keras.layers.Dense(16, activation='relu'))\n",
    "cnn.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "# one GlobalAveragePooling layer\n",
    "simple = keras.Sequential()\n",
    "simple.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "simple.add(keras.layers.GlobalAveragePooling1D())\n",
    "simple.add(keras.layers.Dense(8, activation='relu'))\n",
    "simple.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a0c5b",
   "metadata": {},
   "source": [
    "# 5) 모델 훈련 개시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "022122bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "247/247 [==============================] - 3s 8ms/step - loss: 0.4542 - accuracy: 0.7990 - val_loss: 0.3509 - val_accuracy: 0.8492\n",
      "Epoch 2/5\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.3233 - accuracy: 0.8641 - val_loss: 0.3366 - val_accuracy: 0.8551\n",
      "Epoch 3/5\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.2911 - accuracy: 0.8778 - val_loss: 0.3351 - val_accuracy: 0.8576\n",
      "Epoch 4/5\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2651 - accuracy: 0.8891 - val_loss: 0.3457 - val_accuracy: 0.8555\n",
      "Epoch 5/5\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.2409 - accuracy: 0.8997 - val_loss: 0.3571 - val_accuracy: 0.8552\n",
      "Epoch 1/3\n",
      "247/247 [==============================] - 2s 7ms/step - loss: 0.4387 - accuracy: 0.7942 - val_loss: 0.3379 - val_accuracy: 0.8515\n",
      "Epoch 2/3\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.3007 - accuracy: 0.8737 - val_loss: 0.3258 - val_accuracy: 0.8576\n",
      "Epoch 3/3\n",
      "247/247 [==============================] - 2s 6ms/step - loss: 0.2446 - accuracy: 0.9031 - val_loss: 0.3352 - val_accuracy: 0.8583\n",
      "Epoch 1/3\n",
      "247/247 [==============================] - 2s 5ms/step - loss: 0.5467 - accuracy: 0.7495 - val_loss: 0.3932 - val_accuracy: 0.8382\n",
      "Epoch 2/3\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.3642 - accuracy: 0.8468 - val_loss: 0.3588 - val_accuracy: 0.8439\n",
      "Epoch 3/3\n",
      "247/247 [==============================] - 1s 4ms/step - loss: 0.3368 - accuracy: 0.8586 - val_loss: 0.3537 - val_accuracy: 0.8475\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "lstm.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_lstm = lstm.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "              \n",
    "epochs = 3\n",
    "\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history_cnn = cnn.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "\n",
    "# 1-D CNN과 동일하게 3 epochs로 진행\n",
    "simple.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_simple = simple.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb133d",
   "metadata": {},
   "source": [
    "# 6) Loss, Accuracy 그래프 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775d98ff",
   "metadata": {},
   "source": [
    "## LMTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb323482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history_lstm.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# 그림을 초기화\n",
    "plt.clf()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8d306",
   "metadata": {},
   "source": [
    "## 7) 학습된 Embedding 레이어 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7395dca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embedding_lstm = lstm.layers[0]\n",
    "weights_lstm = embedding_lstm.get_weights()[0]\n",
    "\n",
    "embedding_cnn = cnn.layers[0]\n",
    "weights_cnn = embedding_cnn.get_weights()[0]\n",
    "\n",
    "embedding_simple = simple.layers[0]\n",
    "weights_simple = embedding_simple.get_weights()[0]\n",
    "\n",
    "word2vec_file_path_lstm = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec_lstm.txt'\n",
    "f = open(word2vec_file_path_lstm, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))\n",
    "\n",
    "vectors = lstm.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()\n",
    "\n",
    "word2vec_file_path_cnn = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec_cnn.txt'\n",
    "f = open(word2vec_file_path_cnn, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))\n",
    "\n",
    "vectors = cnn.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()\n",
    "\n",
    "word2vec_file_path_simple = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec_simple.txt'\n",
    "f = open(word2vec_file_path_simple, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))\n",
    "\n",
    "vectors = simple.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()\n",
    "\n",
    "word_vectors_lstm = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path_lstm, binary=False)\n",
    "\n",
    "word_vectors_cnn = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path_cnn, binary=False)\n",
    "\n",
    "word_vectors_simple = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path_simple, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e41a7",
   "metadata": {},
   "source": [
    "## 8) 한국어 Word2Vec 임베딩 활용하여 성능 개선\n",
    "예시 코드\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "word_vectors = Word2VecKeyedVectors.load(word2vec_file_path)\n",
    "vector = word_vectors.wv[‘끝’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54d1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "path = os.getenv('HOME')+'/aiffel/sentiment_classification/ko.bin'\n",
    "ko_vec = Word2Vec.load(path)\n",
    "\n",
    "print(ko_vec.wv[\"배우\"]) # ko_vec[\"배우\"]방식은 deprecated라고 한다.\n",
    "pprint.pprint(ko_vec.wv.most_similar(\"배우\")) #마찬가지로 ko_vec.most_similar() 방식도 deprecated. 지양하자.\n",
    "\n",
    "ko_vec = ko_vec.wv # ko_vec.wv대신 ko_vec을 사용하면 아래에서도 deprecated 경고 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_ko_vec = 10000\n",
    "word_vector_dim_ko_vec = 200\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size_ko_vec, word_vector_dim_ko_vec)\n",
    "\n",
    "for i in range(4,vocab_size_ko_vec):\n",
    "    if index_to_word[i] in ko_vec:\n",
    "        embedding_matrix[i] = ko_vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15be283f",
   "metadata": {},
   "source": [
    "## 모델에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a414436",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "word_vector_dim = 200 #https://github.com/Kyubyong/wordvectors 참고. 한국어 word2vec는 벡터 사이즈가 200이다.\n",
    "\n",
    "# LSTM\n",
    "lstm = keras.Sequential()\n",
    "lstm.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))\n",
    "lstm.add(keras.layers.LSTM(128))\n",
    "lstm.add(keras.layers.Dense(128, activation='relu'))\n",
    "lstm.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm.summary()\n",
    "\n",
    "# 1-D CNN\n",
    "cnn = keras.Sequential()\n",
    "cnn.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))\n",
    "cnn.add(keras.layers.Dropout(0.5))\n",
    "cnn.add(keras.layers.Conv1D(512, 7, activation='relu'))\n",
    "cnn.add(keras.layers.MaxPooling1D(5))\n",
    "cnn.add(keras.layers.Conv1D(512, 7, activation='relu'))\n",
    "cnn.add(keras.layers.GlobalMaxPooling1D())\n",
    "cnn.add(keras.layers.Dense(256, activation='relu'))\n",
    "cnn.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cnn.summary()\n",
    "\n",
    "# one GlobalAveragePooling1D layer\n",
    "simple = keras.Sequential()\n",
    "simple.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))\n",
    "\n",
    "simple.add(keras.layers.GlobalAveragePooling1D())\n",
    "simple.add(keras.layers.Dense(128, activation='relu'))\n",
    "simple.add(keras.layers.Dropout(0.1))\n",
    "simple.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "simple.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01972e2",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030e287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "\n",
    "lstm.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_lstm = lstm.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "cnn.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "history_cnn = cnn.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)\n",
    "                    \n",
    "epochs = 8\n",
    "\n",
    "simple.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_simple = simple.fit(partial_X_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c2e4d",
   "metadata": {},
   "source": [
    "## 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd292fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "results_lstm = lstm.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_lstm)\n",
    "\n",
    "# 1-D CNN\n",
    "results_cnn = cnn.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_cnn)\n",
    "\n",
    "# one GlobalAveragePooling1D layer\n",
    "results_simple = simple.evaluate(X_test, y_test, verbose=2)\n",
    "print(results_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133ee22e",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c59ca2",
   "metadata": {},
   "source": [
    "텍스트 분석을 통해 리뷰가 긍정인지 부정인지를 분류하는 모델을 만드는 것이 목표였다.\n",
    "\n",
    "처음엔 학습된 워드 벡터를 적용하지 않고, 모델을 구성했다.\n",
    "\n",
    "정확도는 LSTM과 MaxPooling1D 레이어를 하나만 사용해 구성한 모델이 84 퍼센트 대였고, 1-D CNN이 유일하게 85 퍼센트를 넘었다.\n",
    "\n",
    "정확도는 목표로 한 85 퍼센트에 근접하거나 넘었지만, 학습한 벡터들을 확인하기 위해 각각의 모델이 내놓은 벡터 값 중 \"배우\"라는 단어의 벡터 값과 가장 유사한 벡터 값을 출력해보니, 세 모델 모두 전체적으로 \"배우\"와 유사하다고 할 수 있는 단어를 반환하지 못했다.\n",
    "\n",
    "그래서 학습된 워드 임베딩을 적용한 모델을 테스트해봤다. (https://github.com/Kyubyong/wordvectors 에서 다운로드 받을 수 있다.)\n",
    "\n",
    "한국어 Word2Vec 파일을 읽어오고, \"배우\"와 유사한 값을 갖는 벡터들을 출력해보니, \"영화배우\", \"연출가\", \"연극배우\" 등 전반적으로 자체 워드 임베딩의 벡터보다 유사한 단어를 출력하는 걸 확인할 수 있었다.\n",
    "\n",
    "이 벡터값들을 각 모델의 임베딩 레이어에 적용하고 학습과 평가를 해보니 생각과는 다른 결과가 나왔다.\n",
    "\n",
    "같은 조건에서 오히려 테스트 정확도가 낮게 나왔고, 모델들의 hyperparameter값을 조정한 후에야 LSTM 모델만 85 퍼센트를 넘었다.\n",
    "\n",
    "올바른 추론인지는 모르곘지만, 첫 번째 epoch부터 training accuracy와 validation accuracy가 높게 나오고, 2~3번쨰 epoch부터는 training accuracy만 오르고 validation accuracy는 오히려 떨어지는 경향을 보이길래 처음부터 빠르게 학습 데이터에 과적합되는 것인지 궁금해서 1-D CNN 모델에 Dropout 레이어를 추가했더니 1-D CNN 모델도 85 퍼센트를 넘었다.\n",
    "\n",
    "하지만 GlobalMaxPooling1D레이어와 GlobalAveragePooling1D레이어 하나만 적용한 모델은 85 퍼센트의 벽을 넘지 못했다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
